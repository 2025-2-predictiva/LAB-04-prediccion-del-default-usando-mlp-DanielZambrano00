{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69057162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from typing import Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score,\n",
    "    confusion_matrix,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f184788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas y configuración global\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "TRAIN_PATH = \"../files/input/train_data.csv.zip\"\n",
    "TEST_PATH = \"../files/input/test_data.csv.zip\"\n",
    "\n",
    "MODEL_FILENAME = \"../files/models/model.pkl.gz\"\n",
    "METRICS_FILENAME = \"../files/output/metrics.json\"\n",
    "\n",
    "CATEGORICAL = [\"SEX\", \"EDUCATION\", \"MARRIAGE\"]\n",
    "N_FOLDS = 10\n",
    "RANDOM_STATE = 420\n",
    "N_JOBS = -1\n",
    "\n",
    "# Rejilla de hiperparámetros para el MLP dentro del pipeline\n",
    "PARAM_GRID = {\n",
    "\"pca__n_components\": [20],\n",
    "\"selectkbest__k\": [15,20], \n",
    "\"classifier__hidden_layer_sizes\": [(50,30,40,60)], \n",
    "\"classifier__alpha\": [0.256], \n",
    "\"classifier__learning_rate\": [\"adaptive\"],\n",
    "\"classifier__activation\": [\"relu\"],\n",
    "\"classifier__solver\": [\"adam\", \"lbfgs\"],\n",
    "\"classifier__learning_rate_init\": [0.001],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2921c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Limpieza y carga de datos\n",
    "# ---------------------------------------------------------------------\n",
    "def clean_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Limpieza según las instrucciones del taller.\"\"\"\n",
    "    # Renombrar columna objetivo\n",
    "    if \"default payment next month\" in df.columns:\n",
    "        df = df.rename(columns={\"default payment next month\": \"default\"})\n",
    "\n",
    "    # Remover columna ID si existe\n",
    "    if \"ID\" in df.columns:\n",
    "        df = df.drop(columns=[\"ID\"])\n",
    "\n",
    "    # Eliminar filas con valores faltantes\n",
    "    df = df.dropna()\n",
    "\n",
    "    # EDUCATION: agrupar valores > 4 en la categoría \"others\" (4)\n",
    "    if \"EDUCATION\" in df.columns:\n",
    "        df[\"EDUCATION\"] = df[\"EDUCATION\"].astype(int)\n",
    "        df.loc[df[\"EDUCATION\"] > 4, \"EDUCATION\"] = 4\n",
    "\n",
    "    \n",
    "    # eliminar registros con EDUCATION == 0 o MARRIAGE == 0\n",
    "    if \"EDUCATION\" in df.columns and \"MARRIAGE\" in df.columns:\n",
    "        df = df.query(\"EDUCATION != 0 and MARRIAGE != 0\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7dfa1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_clean_data(\n",
    "    train_path: str = TRAIN_PATH,\n",
    "    test_path: str = TEST_PATH,\n",
    ") -> Tuple[pd.DataFrame, pd.Series, pd.DataFrame, pd.Series]:\n",
    "    \"\"\"Carga train/test, aplica limpieza y divide en X/y.\"\"\"\n",
    "    train = pd.read_csv(train_path, index_col=False, compression=\"zip\")\n",
    "    test = pd.read_csv(test_path, index_col=False, compression=\"zip\")\n",
    "\n",
    "    train = clean_data(train)\n",
    "    test = clean_data(test)\n",
    "\n",
    "    target = \"default\"\n",
    "\n",
    "    x_train = train.drop(columns=[target])\n",
    "    y_train = train[target].astype(int)\n",
    "\n",
    "    x_test = test.drop(columns=[target])\n",
    "    y_test = test[target].astype(int)\n",
    "\n",
    "    return x_train, y_train, x_test, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c52547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Pipeline + GridSearchCV con MLP\n",
    "# ---------------------------------------------------------------------\n",
    "def make_pipeline() -> Pipeline:\n",
    "    \"\"\"Crea el pipeline con OneHotEncoder + StandardScaler + PCA + SelectKBest + MLP.\"\"\"\n",
    "    x_train, _, _, _ = load_clean_data()\n",
    "\n",
    "    numeric = [c for c in x_train.columns if c not in CATEGORICAL]\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", OneHotEncoder(handle_unknown=\"ignore\"), CATEGORICAL),\n",
    "            (\"num\", StandardScaler(), numeric),\n",
    "        ],\n",
    "        remainder=\"drop\",  # no debería haber más columnas, pero por claridad\n",
    "    )\n",
    "\n",
    "    mlp = MLPClassifier(\n",
    "        random_state=RANDOM_STATE,\n",
    "        max_iter=1000,\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"selectkbest\", SelectKBest(score_func=f_classif, k=\"all\")),\n",
    "            (\"pca\", PCA()),\n",
    "            (\"classifier\", mlp),\n",
    "        ],\n",
    "        verbose=False,\n",
    "    )\n",
    "\n",
    "    return pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a2b3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def make_grid_search(\n",
    "    pipeline: Pipeline,\n",
    "    param_grid=None,\n",
    "    n_folds: int = N_FOLDS,\n",
    "    n_jobs: int = N_JOBS,\n",
    ") -> GridSearchCV:\n",
    "    \"\"\"Envuelve el pipeline en un GridSearchCV usando balanced_accuracy.\"\"\"\n",
    "    if param_grid is None:\n",
    "        param_grid = PARAM_GRID\n",
    "\n",
    "    cv = StratifiedKFold(\n",
    "        n_splits=n_folds,\n",
    "        shuffle=True,\n",
    "        random_state=RANDOM_STATE,\n",
    "    )\n",
    "\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=n_folds,\n",
    "        scoring=\"balanced_accuracy\",\n",
    "        n_jobs=n_jobs,\n",
    "        verbose=0,\n",
    "    )\n",
    "\n",
    "    return grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8be0bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Guardar / cargar modelo\n",
    "# ---------------------------------------------------------------------\n",
    "def save_model(model) -> None:\n",
    "    \"\"\"Guarda el modelo comprimido en MODEL_FILENAME.\"\"\"\n",
    "    os.makedirs(os.path.dirname(MODEL_FILENAME), exist_ok=True)\n",
    "    with gzip.open(MODEL_FILENAME, \"wb\") as f:\n",
    "        pickle.dump(model, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "654e135e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model():\n",
    "    \"\"\"Carga el modelo desde MODEL_FILENAME si existe, sino devuelve None.\"\"\"\n",
    "    if not os.path.exists(MODEL_FILENAME):\n",
    "        return None\n",
    "    with gzip.open(MODEL_FILENAME, \"rb\") as f:\n",
    "        model = pickle.load(f)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e09c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Entrenamiento \n",
    "# ---------------------------------------------------------------------\n",
    "def train_model(model: GridSearchCV) -> None:\n",
    "    \"\"\"Ajusta el GridSearchCV y guarda el mejor modelo (según balanced_accuracy).\"\"\"\n",
    "    x_train, y_train, x_test, y_test = load_clean_data()\n",
    "\n",
    "    # Entrenar GridSearchCV\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    # Comparar con modelo previamente guardado (si existe) usando balanced_accuracy en test\n",
    "    best_model = load_model()\n",
    "    if best_model is not None:\n",
    "        saved_bas = balanced_accuracy_score(y_test, best_model.predict(x_test))\n",
    "        current_bas = balanced_accuracy_score(y_test, model.predict(x_test))\n",
    "        if saved_bas >= current_bas:\n",
    "            # Si el modelo anterior es mejor o igual, lo conservamos\n",
    "            model = best_model\n",
    "\n",
    "    save_model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07f1b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_mlp_model(param_grid=None) -> None:\n",
    "    \"\"\"Función de alto nivel para entrenar el modelo MLP.\"\"\"\n",
    "    pipeline = make_pipeline()\n",
    "    grid = make_grid_search(pipeline, param_grid=param_grid)\n",
    "    train_model(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3d0524f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Métricas y matrices de confusión\n",
    "# ---------------------------------------------------------------------\n",
    "def eval_metrics(model, x_train, y_train, x_test, y_test):\n",
    "    \"\"\"Calcula métricas y matrices de confusión en train y test.\"\"\"\n",
    "\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "\n",
    "    def metrics_dict(y_true, y_pred, dataset):\n",
    "        return {\n",
    "            \"type\": \"metrics\",\n",
    "            \"dataset\": dataset,\n",
    "            \"precision\": float(precision_score(y_true, y_pred, zero_division=0)),\n",
    "            \"balanced_accuracy\": float(balanced_accuracy_score(y_true, y_pred)),\n",
    "            \"recall\": float(recall_score(y_true, y_pred, zero_division=0)),\n",
    "            \"f1_score\": float(f1_score(y_true, y_pred, zero_division=0)),\n",
    "        }\n",
    "\n",
    "    def cm_dict(y_true, y_pred, dataset):\n",
    "        cm = confusion_matrix(y_true.astype(int), y_pred.astype(int), labels=[0, 1])\n",
    "        tn, fp, fn, tp = int(cm[0, 0]), int(cm[0, 1]), int(cm[1, 0]), int(cm[1, 1])\n",
    "        return {\n",
    "            \"type\": \"cm_matrix\",\n",
    "            \"dataset\": dataset,\n",
    "            \"true_0\": {\"predicted_0\": tn, \"predicted_1\": fp},\n",
    "            \"true_1\": {\"predicted_0\": fn, \"predicted_1\": tp},\n",
    "        }\n",
    "\n",
    "    metrics_train = metrics_dict(y_train, y_pred_train, \"train\")\n",
    "    metrics_test = metrics_dict(y_test, y_pred_test, \"test\")\n",
    "    cm_train = cm_dict(y_train, y_pred_train, \"train\")\n",
    "    cm_test = cm_dict(y_test, y_pred_test, \"test\")\n",
    "\n",
    "    return metrics_train, metrics_test, cm_train, cm_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a66a3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_report(\n",
    "    metrics_train,\n",
    "    metrics_test,\n",
    "    cm_train,\n",
    "    cm_test,\n",
    ") -> None:\n",
    "    \"\"\"Escribe metrics.json con 4 líneas (2 métricas + 2 matrices de confusión).\"\"\"\n",
    "    os.makedirs(os.path.dirname(METRICS_FILENAME), exist_ok=True)\n",
    "    with open(METRICS_FILENAME, \"w\", encoding=\"utf-8\", newline=\"\\n\") as f:\n",
    "        f.write(json.dumps(metrics_train) + \"\\n\")\n",
    "        f.write(json.dumps(metrics_test) + \"\\n\")\n",
    "        f.write(json.dumps(cm_train) + \"\\n\")\n",
    "        f.write(json.dumps(cm_test) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "50a50d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def print_report(metrics_train, metrics_test, cm_train=None, cm_test=None) -> None:\n",
    "    \"\"\"Imprime un resumen compacto de métricas (test (train)).\"\"\"\n",
    "\n",
    "    def fmt(name, test_val, train_val):\n",
    "        return f\"{name:>20}: {test_val:.4f} ({train_val:.4f})\"\n",
    "\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Metrics summary (test (train))\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\n",
    "        fmt(\n",
    "            \"Balanced Accuracy\",\n",
    "            metrics_test[\"balanced_accuracy\"],\n",
    "            metrics_train[\"balanced_accuracy\"],\n",
    "        )\n",
    "    )\n",
    "    print(fmt(\"Precision\", metrics_test[\"precision\"], metrics_train[\"precision\"]))\n",
    "    print(fmt(\"Recall\", metrics_test[\"recall\"], metrics_train[\"recall\"]))\n",
    "    print(fmt(\"F1-score\", metrics_test[\"f1_score\"], metrics_train[\"f1_score\"]))\n",
    "    if cm_test and cm_train:\n",
    "        print(\"-\" * 80)\n",
    "        print(\"Confusion matrix (test):\")\n",
    "        print(\n",
    "            f\" true_0 -> predicted_0: {cm_test['true_0']['predicted_0']}, \"\n",
    "            f\"predicted_1: {cm_test['true_0']['predicted_1']}\"\n",
    "        )\n",
    "        print(\n",
    "            f\" true_1 -> predicted_0: {cm_test['true_1']['predicted_0']}, \"\n",
    "            f\"predicted_1: {cm_test['true_1']['predicted_1']}\"\n",
    "        )\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96c838f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_estimator() -> None:\n",
    "    \"\"\"Carga datos, evalúa el modelo guardado y genera metrics.json.\"\"\"\n",
    "    x_train, y_train, x_test, y_test = load_clean_data()\n",
    "    model = load_model()\n",
    "    if model is None:\n",
    "        raise RuntimeError(\"No se encontró el modelo entrenado en files/models.\")\n",
    "\n",
    "    metrics_train, metrics_test, cm_train, cm_test = eval_metrics(\n",
    "        model, x_train, y_train, x_test, y_test\n",
    "    )\n",
    "\n",
    "    save_report(metrics_train, metrics_test, cm_train, cm_test)\n",
    "    print_report(metrics_train, metrics_test, cm_train, cm_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f76fbd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_get_params() -> None:\n",
    "    \"\"\"Imprime todos los parámetros del GridSearchCV guardado.\"\"\"\n",
    "    model = load_model()\n",
    "    if model is None:\n",
    "        print(\"No model found.\")\n",
    "        return\n",
    "    print(\"Get model parameters:\")\n",
    "    for param, value in model.get_params().items():\n",
    "        print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "734f231a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def print_best_model_params() -> None:\n",
    "    \"\"\"Imprime los mejores hiperparámetros encontrados por GridSearchCV.\"\"\"\n",
    "    model = load_model()\n",
    "    if model is None:\n",
    "        print(\"No model found.\")\n",
    "        return\n",
    "    if not hasattr(model, \"best_params_\"):\n",
    "        print(\"El modelo cargado no tiene atributo best_params_.\")\n",
    "        return\n",
    "    print(\"Best model parameters:\")\n",
    "    for param, value in model.best_params_.items():\n",
    "        print(f\"  {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "401ebc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:528: FitFailedWarning: \n",
      "20 fits failed out of a total of 40.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 866, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 654, in fit\n",
      "    Xt = self._fit(X, y, routed_params, raw_params=params)\n",
      "  File \"d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 588, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\joblib\\memory.py\", line 326, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\pipeline.py\", line 1551, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **params.get(\"fit_transform\", {}))\n",
      "  File \"d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 319, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\base.py\", line 1389, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 468, in fit_transform\n",
      "    U, S, _, X, x_is_centered, xp = self._fit(X)\n",
      "  File \"d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 542, in _fit\n",
      "    return self._fit_full(X, n_components, xp, is_array_api_compliant)\n",
      "  File \"d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\decomposition\\_pca.py\", line 556, in _fit_full\n",
      "    raise ValueError(\n",
      "ValueError: n_components=20 must be between 0 and min(n_samples, n_features)=15 with svd_solver='covariance_eigh'\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "d:\\Semestre 2025-2\\Analítica predictiva\\LAB-04-prediccion-del-default-usando-mlp-DanielZambrano00\\.venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [       nan 0.65332711        nan 0.62893563]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "Metrics summary (test (train))\n",
      "--------------------------------------------------------------------------------\n",
      "   Balanced Accuracy: 0.6704 (0.6674)\n",
      "           Precision: 0.6801 (0.7016)\n",
      "              Recall: 0.3903 (0.3822)\n",
      "            F1-score: 0.4960 (0.4949)\n",
      "--------------------------------------------------------------------------------\n",
      "Confusion matrix (test):\n",
      " true_0 -> predicted_0: 6723, predicted_1: 350\n",
      " true_1 -> predicted_0: 1162, predicted_1: 744\n",
      "--------------------------------------------------------------------------------\n",
      "Best model parameters:\n",
      "  classifier__activation: relu\n",
      "  classifier__alpha: 0.256\n",
      "  classifier__hidden_layer_sizes: (50, 30, 40, 60)\n",
      "  classifier__learning_rate: adaptive\n",
      "  classifier__learning_rate_init: 0.001\n",
      "  classifier__solver: adam\n",
      "  pca__n_components: 20\n",
      "  selectkbest__k: 20\n"
     ]
    }
   ],
   "source": [
    "# 6. Ejecución directa del script\n",
    "# ---------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Entrena el modelo MLP y guarda el mejor en files/models/model.pkl.gz\n",
    "    train_mlp_model()\n",
    "\n",
    "    # Evalúa el modelo guardado y genera files/output/metrics.json\n",
    "    check_estimator()\n",
    "\n",
    "    #  imprime los mejores hiperparámetros encontrados\n",
    "    print_best_model_params()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
